{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deexithra-kore/playground/blob/dev/SimpleT5_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0zXr5xIBrZS"
      },
      "outputs": [],
      "source": [
        "!pip install simplet5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_wT7mPvndzd",
        "outputId": "efd3449b-98ff-480b-8391-c0070231abd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas sentencepiece torch>=1.7.0,!=1.8.0 transformers==4.16.2 pytorch-lightning==1.5.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qrf3Te3oMMI"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BEzceDbBxtA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"/home/ubuntu/str-summ/Dec13_train_summarization_final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Pdf6R5d-_eeP"
      },
      "outputs": [],
      "source": [
        "for i in range(len(df_train)):\n",
        "    df_train['source_text'][i] = df_train['source_text'][i] + \"\\n\\n\" + df_train['instruction'][i]\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPe24LSf_eeP"
      },
      "outputs": [],
      "source": [
        "p1 = \"Generate the Problem Statement for the given conversation i.e, a one liner that briefs why the customer has reached out to an agent or the bot.\"\n",
        "p2 = \"For the given conversation, identify and extract key information such as names, important dates, emails, addresses, and any account details. Consider nuances like context, tone, and explicit mentions to grasp the essential information effectively.\"\n",
        "p3 = \"Generate the Emotion of the customer at the start of the given conversation.\"\n",
        "p4 = \"Give the summary for the given conversation.\"\n",
        "p5 = \"Generate the conclusion for the given conversation i.e, the final action taken to resolve the problem.\"\n",
        "p6 = \"Generate the next steps to be performed by the agent for the given conversation.\"\n",
        "\n",
        "st = []\n",
        "tt = []\n",
        "\n",
        "for i in range(len(df_train)):\n",
        "    if df_train['instruction'][i] in [p1,p2,p4]:\n",
        "        st += [df_train['source_text'][i]]\n",
        "        tt += [df_train['target_text'][i]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atOSeIOl_eeP",
        "outputId": "f8ceccda-b3aa-42fd-8b3f-6946014862b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bot: Hi, I'm Bot, your virtual assistant. How ...</td>\n",
              "      <td>Problem Statement:\\nThe customer has been char...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bot: Welcome to our IT Helpdesk! How may I ass...</td>\n",
              "      <td>Conversation Summary:\\nThe customer, Alex Morg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bot: Hello, welcome to TechCare! I'm your digi...</td>\n",
              "      <td>Problem Statement:\\nThe customer's laptop is f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bot: Good day! I'm Sara, your AI assistant. Ho...</td>\n",
              "      <td>Conversation Summary:\\nThe customer reported a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Key Information:\\nUser Id : jake123\\nAlternate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2698</th>\n",
              "      <td>Bot: Hello, I'm Jarvis, your virtual banking a...</td>\n",
              "      <td>Problem Statement:\\nThe customer's money trans...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2699</th>\n",
              "      <td>Bot: Hi! Welcome to our IT support. I'm your v...</td>\n",
              "      <td>Key Information:\\nNone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2700</th>\n",
              "      <td>Bot: Welcome to our IT Helpdesk. How may I ass...</td>\n",
              "      <td>Problem Statement:\\nCustomer is having difficu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2701</th>\n",
              "      <td>Bot: Hello, I'm Eva, your digital assistant. I...</td>\n",
              "      <td>Conversation Summary:\\nThe customer raised an ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>Bot: Hello, I'm Chatbot, your IT digital assis...</td>\n",
              "      <td>Key Information:\\nCustomer Id : G34BU7\\nMobile...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2703 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            source_text  \\\n",
              "0     Bot: Hi, I'm Bot, your virtual assistant. How ...   \n",
              "1     Bot: Welcome to our IT Helpdesk! How may I ass...   \n",
              "2     Bot: Hello, welcome to TechCare! I'm your digi...   \n",
              "3     Bot: Good day! I'm Sara, your AI assistant. Ho...   \n",
              "4     Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "...                                                 ...   \n",
              "2698  Bot: Hello, I'm Jarvis, your virtual banking a...   \n",
              "2699  Bot: Hi! Welcome to our IT support. I'm your v...   \n",
              "2700  Bot: Welcome to our IT Helpdesk. How may I ass...   \n",
              "2701  Bot: Hello, I'm Eva, your digital assistant. I...   \n",
              "2702  Bot: Hello, I'm Chatbot, your IT digital assis...   \n",
              "\n",
              "                                            target_text  \n",
              "0     Problem Statement:\\nThe customer has been char...  \n",
              "1     Conversation Summary:\\nThe customer, Alex Morg...  \n",
              "2     Problem Statement:\\nThe customer's laptop is f...  \n",
              "3     Conversation Summary:\\nThe customer reported a...  \n",
              "4     Key Information:\\nUser Id : jake123\\nAlternate...  \n",
              "...                                                 ...  \n",
              "2698  Problem Statement:\\nThe customer's money trans...  \n",
              "2699                             Key Information:\\nNone  \n",
              "2700  Problem Statement:\\nCustomer is having difficu...  \n",
              "2701  Conversation Summary:\\nThe customer raised an ...  \n",
              "2702  Key Information:\\nCustomer Id : G34BU7\\nMobile...  \n",
              "\n",
              "[2703 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_new = pd.DataFrame({\n",
        "    \"source_text\":st,\n",
        "    \"target_text\":tt\n",
        "})\n",
        "df_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vyUtCQX_eeQ",
        "outputId": "696ac65a-5fbb-418d-9a21-a59d30cd380a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer reached ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1921</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nConversation Summary:\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Problem Statement:\\nThe customer received a hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>Customer: Hi, I've been charged for an interna...</td>\n",
              "      <td>Conversation Summary:\\nThe customer contacted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2465</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer was facing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1443</th>\n",
              "      <td>Bot: Hello, I'm Alex, your digital assistant. ...</td>\n",
              "      <td>Key Information:\\nCustomer's Device : Dell Lat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Key Information:\\nAccount Number : 123456789\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2685</th>\n",
              "      <td>\\nBot: Hello! Welcome to our IT support. How c...</td>\n",
              "      <td>Conversation Summary:\\nThe customer reached ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019</th>\n",
              "      <td>Bot: Hello, I'm Daisy, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer contacted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1375</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Key Information:\\nSoftware Name : Adobe Photos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2703 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            source_text  \\\n",
              "2486  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "1921  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "916   Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "2022  Customer: Hi, I've been charged for an interna...   \n",
              "2465  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "...                                                 ...   \n",
              "1443  Bot: Hello, I'm Alex, your digital assistant. ...   \n",
              "1027  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "2685  \\nBot: Hello! Welcome to our IT support. How c...   \n",
              "2019  Bot: Hello, I'm Daisy, your digital assistant....   \n",
              "1375  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "\n",
              "                                            target_text  \n",
              "2486  Conversation Summary:\\nThe customer reached ou...  \n",
              "1921  Conversation Summary:\\nConversation Summary:\\n...  \n",
              "916   Problem Statement:\\nThe customer received a hi...  \n",
              "2022  Conversation Summary:\\nThe customer contacted ...  \n",
              "2465  Conversation Summary:\\nThe customer was facing...  \n",
              "...                                                 ...  \n",
              "1443  Key Information:\\nCustomer's Device : Dell Lat...  \n",
              "1027  Key Information:\\nAccount Number : 123456789\\n...  \n",
              "2685  Conversation Summary:\\nThe customer reached ou...  \n",
              "2019  Conversation Summary:\\nThe customer contacted ...  \n",
              "1375  Key Information:\\nSoftware Name : Adobe Photos...  \n",
              "\n",
              "[2703 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.drop(columns=[\"Unnamed: 0\", \"instruction\"], inplace=True)\n",
        "df_train = df_train.sample(frac=1)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fl_HSl3_eeQ",
        "outputId": "9acd5de5-e863-4d25-fafb-51123d951d92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>source_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2486</td>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer reached ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1921</td>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nConversation Summary:\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>916</td>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Problem Statement:\\nThe customer received a hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022</td>\n",
              "      <td>Customer: Hi, I've been charged for an interna...</td>\n",
              "      <td>Conversation Summary:\\nThe customer contacted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2465</td>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer was facing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2698</th>\n",
              "      <td>1443</td>\n",
              "      <td>Bot: Hello, I'm Alex, your digital assistant. ...</td>\n",
              "      <td>Key Information:\\nCustomer's Device : Dell Lat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2699</th>\n",
              "      <td>1027</td>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Key Information:\\nAccount Number : 123456789\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2700</th>\n",
              "      <td>2685</td>\n",
              "      <td>\\nBot: Hello! Welcome to our IT support. How c...</td>\n",
              "      <td>Conversation Summary:\\nThe customer reached ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2701</th>\n",
              "      <td>2019</td>\n",
              "      <td>Bot: Hello, I'm Daisy, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer contacted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>1375</td>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Key Information:\\nSoftware Name : Adobe Photos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2703 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index                                        source_text  \\\n",
              "0      2486  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "1      1921  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "2       916  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "3      2022  Customer: Hi, I've been charged for an interna...   \n",
              "4      2465  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "...     ...                                                ...   \n",
              "2698   1443  Bot: Hello, I'm Alex, your digital assistant. ...   \n",
              "2699   1027  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "2700   2685  \\nBot: Hello! Welcome to our IT support. How c...   \n",
              "2701   2019  Bot: Hello, I'm Daisy, your digital assistant....   \n",
              "2702   1375  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "\n",
              "                                            target_text  \n",
              "0     Conversation Summary:\\nThe customer reached ou...  \n",
              "1     Conversation Summary:\\nConversation Summary:\\n...  \n",
              "2     Problem Statement:\\nThe customer received a hi...  \n",
              "3     Conversation Summary:\\nThe customer contacted ...  \n",
              "4     Conversation Summary:\\nThe customer was facing...  \n",
              "...                                                 ...  \n",
              "2698  Key Information:\\nCustomer's Device : Dell Lat...  \n",
              "2699  Key Information:\\nAccount Number : 123456789\\n...  \n",
              "2700  Conversation Summary:\\nThe customer reached ou...  \n",
              "2701  Conversation Summary:\\nThe customer contacted ...  \n",
              "2702  Key Information:\\nSoftware Name : Adobe Photos...  \n",
              "\n",
              "[2703 rows x 3 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.reset_index(inplace=True)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KcqKXLQ_eeQ",
        "outputId": "8982e175-c803-46b1-d758-4ffca7cfe452"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_text</th>\n",
              "      <th>target_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer reached ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nConversation Summary:\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Problem Statement:\\nThe customer received a hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Customer: Hi, I've been charged for an interna...</td>\n",
              "      <td>Conversation Summary:\\nThe customer contacted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer was facing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2698</th>\n",
              "      <td>Bot: Hello, I'm Alex, your digital assistant. ...</td>\n",
              "      <td>Key Information:\\nCustomer's Device : Dell Lat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2699</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Key Information:\\nAccount Number : 123456789\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2700</th>\n",
              "      <td>\\nBot: Hello! Welcome to our IT support. How c...</td>\n",
              "      <td>Conversation Summary:\\nThe customer reached ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2701</th>\n",
              "      <td>Bot: Hello, I'm Daisy, your digital assistant....</td>\n",
              "      <td>Conversation Summary:\\nThe customer contacted ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2702</th>\n",
              "      <td>Bot: Hello, I'm Alexa, your digital assistant....</td>\n",
              "      <td>Key Information:\\nSoftware Name : Adobe Photos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2703 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            source_text  \\\n",
              "0     Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "1     Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "2     Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "3     Customer: Hi, I've been charged for an interna...   \n",
              "4     Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "...                                                 ...   \n",
              "2698  Bot: Hello, I'm Alex, your digital assistant. ...   \n",
              "2699  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "2700  \\nBot: Hello! Welcome to our IT support. How c...   \n",
              "2701  Bot: Hello, I'm Daisy, your digital assistant....   \n",
              "2702  Bot: Hello, I'm Alexa, your digital assistant....   \n",
              "\n",
              "                                            target_text  \n",
              "0     Conversation Summary:\\nThe customer reached ou...  \n",
              "1     Conversation Summary:\\nConversation Summary:\\n...  \n",
              "2     Problem Statement:\\nThe customer received a hi...  \n",
              "3     Conversation Summary:\\nThe customer contacted ...  \n",
              "4     Conversation Summary:\\nThe customer was facing...  \n",
              "...                                                 ...  \n",
              "2698  Key Information:\\nCustomer's Device : Dell Lat...  \n",
              "2699  Key Information:\\nAccount Number : 123456789\\n...  \n",
              "2700  Conversation Summary:\\nThe customer reached ou...  \n",
              "2701  Conversation Summary:\\nThe customer contacted ...  \n",
              "2702  Key Information:\\nSoftware Name : Adobe Photos...  \n",
              "\n",
              "[2703 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.drop(columns=[\"index\"], inplace=True)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876,
          "referenced_widgets": [
            "79fb0ef4f261427bb0050d056088875c",
            "70bef647326448aaae5fb5cfb2b845cb",
            "6cf2813a0154436ca2be1ff3c542649b",
            "b1fab192919243808344b341039503b7",
            "64e61411583f47d58789563f982c5dcc",
            "4f722a76a556440d9f5d5a6e414a526a",
            "fccaa54662044d0e96796a7ae8bacf1a",
            "bf4b606f93814f9d996e8c3f41d7caf6",
            "2bfe9c42c25e44a480438fb5333bf352",
            "1efa939df64148c4b49646933c72dd68",
            "f11c4e5bdbc14898a8f7e4c0fa8e4b98",
            "becba7169d8249ec8926de275f2f8c16",
            "5f6e50082d4f4f3fa2277cfbdea58644",
            "b19d651940b541b6a94ce5f24c767f1a",
            "aa3b93fb5baf456e9808f28112b860a8",
            "f2ac66de89f24c15a56ab84ec8c53917",
            "968e6348f3ff41bc93b2e850ba8d83ad",
            "95665c820724406a9bd9cc99ffa9f3ca",
            "0dbed5291b3c445baf19cafc785e359c",
            "b090980aed3f4269863f8df32c03f89a",
            "dafd04e9132e410c86f84111aba86911",
            "f2813335be5a4ffaae5d95476b9658e1",
            "720ada6eeaa24da98690e701e6900597",
            "fdef11975d24467a86f028a3efc09715",
            "1a2031ac286d406ba29f0347225b0ec4",
            "6a35ec5f0a0a4d4097ad51409df18fe1",
            "ec0bab8d99df4f6890deef8a0323dcc4",
            "40d0ca71dddb438bba433cb1766ee1da",
            "6fadf4d589d245f09c979b91f91185b2"
          ]
        },
        "id": "KhpTktkgB3Rs",
        "outputId": "23895e68-170e-4f24-9ba5-d8b2a0a09c6e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 247 M \n",
            "-----------------------------------------------------\n",
            "247 M     Trainable params\n",
            "0         Non-trainable params\n",
            "247 M     Total params\n",
            "990.311   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "720ada6eeaa24da98690e701e6900597",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "Global seed set to 42\n",
            "/opt/conda/envs/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdef11975d24467a86f028a3efc09715",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a2031ac286d406ba29f0347225b0ec4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a35ec5f0a0a4d4097ad51409df18fe1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec0bab8d99df4f6890deef8a0323dcc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40d0ca71dddb438bba433cb1766ee1da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fadf4d589d245f09c979b91f91185b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from simplet5 import SimpleT5\n",
        "\n",
        "model = SimpleT5()\n",
        "model.from_pretrained(model_type=\"t5\", model_name=\"google/flan-t5-base\")\n",
        "model.train(train_df=df_new,\n",
        "            outputdir=\"outputs_Dec13_summ_FlanT5base_5epochs\",\n",
        "            # precision=16,\n",
        "            eval_df=df_new[:20],\n",
        "            source_max_token_len=1024,\n",
        "            target_max_token_len=128,\n",
        "            save_only_last_epoch= True,\n",
        "            batch_size=2, max_epochs=5, use_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YiJXur4_eeR",
        "outputId": "0d330f44-4905-432e-f657-deccd7eac41e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Falcon_1b_lora.ipynb  __pycache__     outputs\t   wandb\n",
            "Untitled28.ipynb      lightning_logs  simplet5.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm_66ylQExa-"
      },
      "outputs": [],
      "source": [
        "from simplet5 import SimpleT5\n",
        "model = SimpleT5()\n",
        "# let's load the trained model for inferencing:\n",
        "model.load_model(\"swt5\",\"../notebooks/outputs_Dec12_summ_FlanT5Large_5epochs/simplet5-epoch-14-train-loss-0.3333-val-loss-0.1817\", use_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8U831k1_eeR"
      },
      "outputs": [],
      "source": [
        "conv='''Customer: request item\n",
        "Bot: IMPORTANT: ChatNow is not yet approved for Bosnia. Please call your local Service Desk for IT Support.\n",
        "\n",
        "Thank you for contacting the Lilly IT Service Desk! Please use the scroll arrow to find the language you would like to chat in, and then click the language from the options below to begin.\n",
        "\n",
        "PRIVACY STATEMENT: All conversation in this chat window will be logged as part of your IT ticket for service to assist with your request. Please refrain from sharing any personal information within the chat. For further information on how your personal information may be processed, please see your local workforce privacy notice. [Translations Available Here](https://collab.lilly.com/sites/PrivacyStatementTranslated)\n",
        "Bot: Please select the language before proceeding. English, Spanish, French.\n",
        "Customer: English\n",
        "Bot: Thank you. Your language has been set to English. Currently, there are no outages.\n",
        "Bot: What service or item are you looking for?\n",
        "Customer: laptop\n",
        "Bot: Did you mean one of these? Laptop - Standard for New Contractor Employee, Laptop - Standard, Privacy Screen - Laptop Lenovo X1, Desktop/Laptop Computing & Support, Cases - Backpack Oversized (US Only), M&Q PR Desktop Support – Report a New Issue, M&Q PR Desktop Support – Report a New Issue, 3D- Stereo Glasses, MIDAS-iManage Service Request, Remove Excess Hardware, Devices for International Travel\n",
        "Customer: Privacy Screen - Laptop Lenovo X1\n",
        "Bot: Please follow the link and use the self service form for this: [Form Link](https://lillyqa.service-now.com/ec?id=sc_cat_item&sys_id=2520bd590fb796005200a218b1050e33).\n",
        "Bot: Is there anything else I can help you with?\n",
        "Customer: Yes\n",
        "Bot: How else can I help you? You can either select from the available options, or if you'd like, feel free to rephrase your question in a way that helps me better understand your needs. Should you want to talk to an agent directly, please type Agent.\n",
        "1. Show open tickets\n",
        "2. Request item\n",
        "3. Show outages\n",
        "4. Search knowledge\n",
        "5. Create incident\n",
        "6. Unlock iOS Device\n",
        "7. Reset Password\n",
        "8. Show my approvals\n",
        "Customer: agent\n",
        "Bot: Are you sure, you want me to transfer to an agent?\n",
        "Customer: Yes\n",
        "Agent: I will need to get an agent on the line to help you. Please hold while I find an available agent.\n",
        "Agent: Transferred to another agent now you are in Queue\n",
        "Agent: Thank you for waiting. You are now connected with Ridhima.\n",
        "Agent: Ridhima has now closed this conversation. Please reach out to us if you need any assistance again.\n",
        "Customer: CSAT Rating\n",
        "Bot: Thank you for choosing ChatNow.\n",
        "Bot: Is there anything else I can help you with?\n",
        "Customer: Yes\n",
        "Agent: How else can I help you? You can either select from the available options, or if you'd like, feel free to rephrase your question in a way that helps me better understand your needs'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8573c9W2_eeR"
      },
      "outputs": [],
      "source": [
        "conv = '''Bot: Hi, I'm Giga, your virtual assistant. I'm here to help you with things like, billing, appointments, tech support, and more. So tell me, how may I help you?\n",
        "Customer: Appointment\n",
        "Bot: First, let's look up your account.\n",
        "Bot: Please enter your email, phone number, or account number.\n",
        "Customer: Ticket\n",
        "Bot: I didn't quite get that.\n",
        "Customer: Live chat\n",
        "Bot: I'll get someone to help, but let me ask a few questions to make sure I find the right person\n",
        "Bot: Is this for a residential or business account? Residential, Business\n",
        "Customer: Residential\n",
        "Bot: So I don't connect you to the wrong agent, choose from the options below. Products and Sales, Billing and Account, Payment Arrangements / Collections, Technical Support, I'm a new customer\n",
        "Customer: Technical Support\n",
        "Bot: Which of these do you need help with? Internet, TV, Voice, Frontier Secure\n",
        "Customer: Internet\n",
        "Bot: Which Internet service is it? Fiber Internet, Frontier Internet, Other Frontier Internet Services\n",
        "Customer: Frontier Internet\n",
        "Bot: OK.\n",
        "Bot: Tell me just your first name.\n",
        "Customer: Paul\n",
        "Bot: And your last name?\n",
        "Customer: Cook\n",
        "Bot: What's the best phone number for you?\n",
        "Customer: 9519705607\n",
        "Bot: Next, tell me your email address.\n",
        "Customer: Cooksnest@aol.com\n",
        "Bot: Thanks\n",
        "Bot: One moment while I get someone to help.\n",
        "Bot: Thank you for waiting. You are now connected with Lordilyn\n",
        "Agent: Hi Paul! Welcome to our technical support chat. I see that you need help with your service. Let me access your account to check what's going on. Could you please provide your account number?\n",
        "Customer: I have an appt just trying to change\n",
        "Customer: 6204871\n",
        "Agent: Sure. I can help you with that. But are you aware that you can easily change or reschedule it using the Myfrontier App or the Frontier website?\n",
        "Agent: To make things more convenient, download our MyFrontierApp on your wireless device. It provides easy access to your account, allowing you to update information and track your ticket status. Available for iPhone and Android:\n",
        "\n",
        "iPhone users, get it from the App Store: https://apps.apple.com/us/developer/frontier-communications/id898149096\n",
        "Android users, find it on the Google Play Store: https://play.google.com/store/apps/details?id=com.frontier.selfserve\n",
        "\n",
        "We hope these resources improve your Frontier experience. If you have any further questions or need assistance, feel free to reach out. We're here to help.\n",
        "Agent: Thank you for providing your ticket number.\n",
        "Customer: My internet is down\n",
        "Agent: Please stay on this chat.\n",
        "Customer: Need Saturday 11/18 8am to noon\n",
        "Agent: Oh no. I do apologize that your internet is out. Let me reschedule it from our end.\n",
        "Customer: Ticket is for tech to come out\n",
        "Agent: Alright. I'll get back to you real quick.\n",
        "Customer: Time was available but it wouldn’t let me save it to my ticket\n",
        "Agent: Thank you for patiently waiting, Paul.\n",
        "Customer: Ty\n",
        "Agent: I see here the ticket number #6204871\n",
        "Appointment Window : 01:00:00 PM - 05:00:00 PM\n",
        "Contact Number :9519705607\n",
        "Customer: Yes but needs to change to Sat 11/18 8-11\n",
        "Agent: As I understand you need to move it to 11/18/23 between 8:00-12:00 pm. Am I correct?\n",
        "Customer: Dr appt conflict\n",
        "Customer: Yes please\n",
        "Agent: Oh, I understand it was an inconvenience to adjust your schedule. No worries, I got you, Paul.\n",
        "Customer: Thank you\n",
        "Agent: You're welcome, Please stay in this chat.\n",
        "Customer: Will do\n",
        "Agent: Alright.\n",
        "Customer: Ticket changed?\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Agent: Still checking if the 11/18/23 is available on the list.\n",
        "Customer: It was available on my list as well as Saturday 11/18 1-5pm\n",
        "Customer: I will take either\n",
        "Agent: I see. on our system, the only available date shown on the list is the 11/16/23\n",
        "Agent: But please hold, I coordinate it with my lead.\n",
        "Customer: Thursday was open\n",
        "Customer: Friday was open\n",
        "Customer: saturday\n",
        "Customer: monday\n",
        "Customer: My internet is down and has been for days\n",
        "Customer: No tv no phone safari\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Customer: Please help\n",
        "Agent: I understand the importance of having working internet and I want you to know that we are committed to restoring your services\n",
        "Customer: Thank you please\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Agent: Running a line test.\n",
        "Customer: Okay\n",
        "Agent: Alright.\n",
        "Customer: Earlier showed no power from box to router\n",
        "Customer: Router is RED or offline\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Customer: Garage box has power plus used different outlet and transformer has green light on unit\n",
        "Customer: unplufged for 1 hour , nothing\n",
        "Agent: Thank you for patiently waiting, I am happy to say that the ticket was successfully rescheduled to 11/18/23 8:00-12:00 pm.\n",
        "Customer: router unplugged and reset , nothing\n",
        "Customer: Okay perfect , thank you L\n",
        "Customer: Appreciate it\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Customer: Are we done then?\n",
        "Agent: Alright, After running a line test.\n",
        "Customer: Anything???\n",
        "Agent: I confirmed that the reason why your internet is out is because the fiber box is out of service.\n",
        "Customer: Makes sense , it’s about 10 plus years old\n",
        "Agent: Oh, that was too old.\n",
        "Agent: Have you experienced a power outage?\n",
        "Customer: Router is 15-20 years old from Verizon\n",
        "Agent: GreenwaveG1100.jpg, https://bots.kore.ai/api/getMediaStream/agentdesktop/o-6d4107d4-d98f-5659-93b7-d4749098b15d/f-00d33db1-6339-5694-9dd7-dff62a306241.jpg?n=5495586654&s=IlU1YUlkSEUxUFVITDEwR1pyenZPVzd1aitTMzF2VVVaYlI3bkRyWmxZaWM9Ig$$\n",
        "Customer: Garage box 10 plus from frontier\n",
        "Agent: Does this look like your router?\n",
        "Customer: No outage here\n",
        "Customer: Looks similar but not the same\n",
        "Agent: nvg448BQ.png, https://bots.kore.ai/api/getMediaStream/agentdesktop/o-6d4107d4-d98f-5659-93b7-d4749098b15d/f-fb3d388d-938b-5848-a340-60f9034ab276.png?n=55714277&s=IlhEVjMvSkUzazJsMTU4d053bDczOFZTT0l5N01ZQmM2dGdHRldMWmhZS0E9Ig$$\n",
        "Agent: This one?\n",
        "Customer: From verizon\n",
        "Customer: Red light in front\n",
        "Customer: plus 1 more light\n",
        "Customer: then a button\n",
        "Agent: Oh, I see.\n",
        "Agent: Have you tried to unplug it and leave it unplug for a minute or two?\n",
        "Customer: looks like first one but not identical\n",
        "Agent: alcatel0100.jpg, https://bots.kore.ai/api/getMediaStream/agentdesktop/o-6d4107d4-d98f-5659-93b7-d4749098b15d/f-546d17cd-20c0-5c77-9f08-f398ade62a95.jpg?n=1290584&s=ImRjWkM4Vm4zZ0IxcXp2QXpsdWlvb25jbm90M3JvZWJUSDdkaVdmazdOelU9Ig$$\n",
        "Customer: Yes I have reset router more than 15 timrs\n",
        "Customer: Pressed reset button on back\n",
        "Agent: Not the router but the fiber box which is the source of all connections.\n",
        "Customer: Pressed button infront\n",
        "Customer: Yes fiber box unplugged 5 minutes then 1 hour and switched to a outplug that was guaranteed working\n",
        "Customer: Fiber box black transformer unit has small green light on\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Customer: Fiber box all sealed and different than your picture\n",
        "Customer: mine are original units\n",
        "Agent: I see. I can see here that you already did the right thing but still nothing is working. The best resolution for that is to wait for the technician to come over.\n",
        "Customer: Okay probably need new everything\n",
        "Customer: old stuff here\n",
        "Customer: Original owners of equipment\n",
        "Customer: Thank you for your help\n",
        "Agent: Since our technician will visit you on the 18th, I know that they will replace your frontier box.\n",
        "Customer: Okay thank you and how about router?\n",
        "Agent: And I see here that you are still using the outdated router, If I'm not mistaken, this is, Greenwave G1100.\n",
        "Agent: The updated router you should have is the NVG468MQ.\n",
        "Customer: Probably skinny unit with DFS in front\n",
        "Customer: Issued by VERIZON\n",
        "Agent: Are you referring to the router or the fiber box?\n",
        "Customer: Router\n",
        "Customer: Fiber box is sealed\n",
        "Agent: Hmmm, Is it possible to check the model  number of it?\n",
        "Customer: Router?\n",
        "Customer: Or box?\n",
        "Agent: Router, please.\n",
        "Customer: Yes it’s a Verizon unit G1100\n",
        "Agent: GreenwaveG1100.jpg, https://bots.kore.ai/api/getMediaStream/agentdesktop/o-6d4107d4-d98f-5659-93b7-d4749098b15d/f-ca61a20d-55c3-5658-a7f9-1ffa472a3763.jpg?n=1240118346&s=IkRXWWpEbjNwS2tFazlBR01LSGg2M1ZuYnV0YXkyUXpYZU9MeE9uYnJrdTQ9Ig$$\n",
        "Agent: I confirmed that this is the router that should be replaced.\n",
        "Customer: Looks like that\n",
        "Agent: Our field technician knows about it, Let us wait for the technician to come out.\n",
        "Agent: I really appreciate your patience as we’ve gone through all of this. If I missed something or you’ve got additional questions, let me know. Otherwise, have an excellent rest of your week!\n",
        "Customer: Okay again thank you for all your help\n",
        "Customer: THANK YOU\n",
        "Agent: You're most welcome, Paul.\n",
        "Agent: Always take care.\n",
        "Agent: It was my pleasure assisting you today. If you need further assistance in the future, you may visit our website at frontier.com or use the MyFrontier Mobile app. Have a wonderful evening!\n",
        "Agent: Conversation is Closed by Customer. If you’re sure that the customer has received a resolution, please close this conversation'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQoh5yyu_eeR"
      },
      "outputs": [],
      "source": [
        "conv = \"\"\"BOT:You have $4000 in your account\n",
        "BOT:Let me know if you need any other assistance\n",
        "CUSTOMER:can you pay bill\n",
        "BOT:Would you like to transfer to a registered biller or to a new biller\n",
        "CUSTOMER:Existing\n",
        "BOT:Enter biller name\n",
        "CUSTOMER:Vodafone\n",
        "BOT:How much would you like to pay?\n",
        "CUSTOMER:2432\n",
        "BOT:Thank you. Task - Pay Bill - is completed\n",
        "BOT:Let me know if you need any other assistance\n",
        "CUSTOMER:can you connect me to agent\n",
        "BOT:I will need to get an agent on the line to help you with that. Please wait while I find an available agent. BOT:Thank you for waiting. You are now connected with VenuGopal\n",
        "AGENT:Agent said something in a template\n",
        "AGENT:can you send me the image\n",
        "CUSTOMER:sure\n",
        "AGENT:hello\n",
        "AGENT:giga is virtual assistant\n",
        "CUSTOMER:am done\n",
        "CUSTOMER:you can cloose now\n",
        "BOT:VenuGopal has now closed this conversation. Please reach out to us if you need any assistance again.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEPsIeHe_eeS",
        "outputId": "5ec3fa2c-fb19-45c1-9f1a-d4161420979e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Conversation Summary: The customer reached out to customer care for assistance with a bill payment. After the initial conversation, the customer was transferred to VenuGopal for further assistance.']"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt1 = \"Generate the Problem Statement for the given conversation i.e, a one liner that briefs why the customer has reached out to an agent or the bot.\"\n",
        "prompt2 = \"For the given conversation, identify and extract key information such as names, important dates, emails, addresses, and any account details. Consider nuances like context, tone, and explicit mentions to grasp the essential information effectively.\"\n",
        "prompt3 = \"Generate the Emotion of the customer at the start of the given conversation.\"\n",
        "prompt4 = \"Give the summary for the given conversation.\"\n",
        "prompt5 = \"Generate the conclusion for the given conversation i.e, the final action taken to resolve the problem.\"\n",
        "prompt6 = \"Generate the next steps to be performed by the agent for the given conversation.\"\n",
        "prompt = [prompt1,prompt2,prompt3,prompt4,prompt5,prompt6]\n",
        "# model.predict(conv+\"\\n\\n\"+prompt4, max_length =512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17-BzTeE_eeS",
        "outputId": "80e73191-84d6-45c0-8d63-1d04ff3218b6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">18</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #808000; text-decoration-color: #808000\">Consumer:I appreciate your time.</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #808000; text-decoration-color: #808000\">Consumer:Have a great day.\"\"\"</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>18 model.predict(prompt2+<span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\\n\"</span>+conv, max_length =<span style=\"color: #0000ff; text-decoration-color: #0000ff\">512</span>)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'prompt2'</span> is not defined\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m18\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[33mConsumer:I appreciate your time.\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[33mConsumer:Have a great day.\u001b[0m\u001b[33m\"\"\"\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m18 model.predict(prompt2+\u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\"\u001b[0m+conv, max_length =\u001b[94m512\u001b[0m)                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'prompt2'\u001b[0m is not defined\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "conv = \"\"\"Consumer:Can you tell me what the $18 is?\n",
        "Consumer:Hello?\n",
        "Consumer:There\n",
        "Agent:Hello, Josh! I apologize for any confusion on my end. Im not sure what you mean by that. Is this in regards to a charge?\n",
        "Consumer:Yes\n",
        "Consumer:I have an $18.00 balance and I can’t see what it is for.\n",
        "Agent:Could you please clarify the last 2 digits of the account this is in regards to?\n",
        "Consumer:Just curious to see if you can jog my memory\n",
        "Consumer:Sure\n",
        "Consumer:61\n",
        "Agent:Thank you for that additional information! Please allow me just a moment to review the account!\n",
        "Consumer:Of course\n",
        "Agent:Thank you for your patience! While reviewing the account, I see that there are 2 Uber charges from 5/4/18. There was one for $16 and another for $2.\n",
        "Consumer:Thank you for jogging my memory. That makes sense.\n",
        "Consumer:I appreciate your time.\n",
        "Consumer:Have a great day.\"\"\"\n",
        "\n",
        "model.predict(prompt2+\"\\n\\n\"+conv, max_length =512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG_rkfp7_eeS",
        "outputId": "c02148ee-62d0-4988-b7b4-4fbcc788e534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Conversation Summary: The customer reached out to customer care due to an issue with their internet connection. The bot initially tried to understand the issue and then transferred the call to the human agent, Lordilyn. After confirming the customer's status, the chat was transferred to Agent John. The agent confirmed that the customer had already reset the router more than 15 timrs and assured them of a resolution. The customer also reported a power outage from the Frontier Internet Router. The agent confirmed that the customer has been informed about the technician's visit.\"]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv, max_length =512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXTUnUjv_eeS",
        "outputId": "4221440a-c7fd-48ea-c8ca-82ef27a29082"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Conversation Summary: The customer reached out to customer care due to an issue with their internet connection. The bot initially tried to understand the issue and then transferred the call to the human agent, Lordilyn. After confirming the customer's status, the chat was transferred to Agent John. The agent confirmed that the customer had already reset the router more than 15 timrs and assured them of a resolution. The customer also reported a power outage from the Frontier Internet Router. The agent confirmed that the customer has been informed about the technician's visit.\"]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv, max_length =512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbLuSU0GExYS"
      },
      "outputs": [],
      "source": [
        "conv='''Bot: Hi, I'm Giga, your virtual assistant. I'm here to help you with things like, billing, appointments, tech support, and more. So tell me, how may I help you?\n",
        "Customer: service upgrade\n",
        "Bot: Okay. Are you a current Frontier customer? Yes, No\n",
        "Customer: yes\n",
        "Bot: Welcome! Let me ask a couple of questions before I connect you.\n",
        "Bot: Tell me just your first name.\n",
        "Customer: vincent\n",
        "Bot: And your last name?\n",
        "Customer: herrera\n",
        "Bot: What's the best phone number for you?\n",
        "Customer: 6263736072\n",
        "Bot: Next, tell me your email address.\n",
        "Customer: dank08@gmail.com\n",
        "Bot: Thanks\n",
        "Bot: One moment while I get someone to help.\n",
        "Agent: Thank you for waiting. You are now connected with Patrick\n",
        "Agent: Hi , thank you for reaching Frontier. I see that you have questions about upgrade?\n",
        "Customer: Yes, so last night a chatted with a rep who directed me to filling out an online form to take advantage of an offer I received via email.  1gig up/down for $60 per month until 2025 and a router upgrade.  I filled out the form last night.  However, the email I received back said my install order was canceled and just chat with a rep to upgrade.\n",
        "Customer: The install order was 079018119\n",
        "Customer: That brings me to this evening where I'm hoping to complete the upgrade.\n",
        "Agent: I completely apologize for the inconvenience. I will go ahead and check this order for you Vincent.\n",
        "Customer: Thank you.\n",
        "Agent: Can you please confirm to me the service address, please?\n",
        "Customer: 5123 columbia drive, fontana, ca\n",
        "Agent: Thank you. One moment.\n",
        "Agent: Thank you for holding as per checked here the order was not canceled it was successfully processed Vincent, the Installation is on 11/25/2023.\n",
        "Customer: This is the email message I received 9 hours ago We see you requested a new install\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Agent: I see, No worries Vincent, your order here is secure and it wasn't canceled. Disregard that email Vincent .\n",
        "Customer: Can you explain what's going on then? I asked the chat rep last night why does a technician need to come out if I have service already?\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Agent: I see, our tech team is only to check the device if it is in good condition that's it Vincent.\n",
        "Customer: Well you can imagine my confusion.  Are you able to send a follow up email confirming the appointment?  Also please confirm the appointment is when the speed upgrade will happen?\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Agent: As per checked here the appointment regarding the order it will take effect on 11/25/2023.\n",
        "Agent: The reason why it will take effect on  11/25/2023 it's because this is a new order Vincent.\n",
        "Customer: Ok, there is still no explanation for the email I received. So I understand, there is not a method for starting the upgrade now?\n",
        "Agent: You’ve not responded to this customer for a while. If you’re sure that the customer has received a resolution, please close this conversation.\n",
        "Agent: Since this is a new order Vincent, All we need to do is to wait for the due date and it will happen on  079018119.\n",
        "Customer: Very well.  Thank you.\n",
        "Agent: Great, aside from this is there anything I can help you with?\n",
        "Customer: No, thank you.  Goodnight.\n",
        "Agent: It was my pleasure assisting you today and I appreciate your patience with me all throughout our conversation. If you need further assistance in the future, you may visit our website at frontier.com or use the MyFrontier Mobile app. Have a wonderful day, Vincent !\n",
        "Agent: Patrick has now closed this conversation. Please reach out to us if you need any assistance again.\n",
        "Agent: survey_process_initiated\n",
        "Customer: CSAT Rating\n",
        "Agent: Thank you for contacting Frontier! Your feedback is very important to us. Please share your experience with Frontier Chat today n this brief survey'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU-ZEPIG_eeS"
      },
      "outputs": [],
      "source": [
        "conv='''Bot: Hi, I'm Giga, your virtual assistant. Give me a moment while I look up your account details.\n",
        "Bot: Bryan, I have your account details now, how may I help you?\n",
        "Customer: How does the eeros booster work?\n",
        "Bot: Almost done, thanks for your patience.\n",
        "Bot: I can help with internet troubleshooting.\n",
        "Bot: What issue are you experiencing? Wi-Fi connection, Can't connect plugged into modem, Slow speed, Can't access webpage, Something else\n",
        "Customer: Something else\n",
        "Bot: This issue will be best handled by an agent.\n",
        "Bot: One moment while I get someone to help.\n",
        "Bot: Thank you for waiting. You are now connected with Mark Dave\n",
        "Agent: Hi, Bryan! Welcome to our Fiber technical support chat. I apologize for the issues you are having with your internet services. Rest assured, I can check this for you. To begin with, may I have your account number and name, please?\n",
        "Agent: Just checking if you are still there, I haven't heard from you for a bit. I'll be here for few more minutes if you need my help.\n",
        "Agent: Thank you for contacting Technical Support. Due to inactivity, this chat session will be closed. If you need further assistance, please visit our website at Frontier.com or utilize the MyFrontier Mobile app. Feel free to start a new chat if you have any additional questions. Have a great rest of your day!\n",
        "Agent: Mark Dave has now closed this conversation. Please reach out to us if you need any assistance again.\n",
        "Agent: survey_process_initiated\n",
        "Agent: survey_eligibility_conf'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5w1NOcX_eeS",
        "outputId": "055eee96-0594-4b6d-a6c7-424b3d1a57a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Key Information: Account Number : Bryan Name : Mark Dave Survey_process_initiated : Survey_eligibility_conf']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv+'\\n\\n'+p2, max_length =512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6plmcnl_eeS",
        "outputId": "e62de32d-9f8d-472e-aad9-eb9dbb5727c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Conversation Summary: The customer reached out to customer care due to issues with their internet services. After initial troubleshooting attempts by the bot, the call was transferred to Agent Mark Dave. However, due to inactivity, the chat session was closed.']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv, max_length =512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmqjoyVTO0em",
        "outputId": "59f25dcf-c4ce-41f3-ee86-62fd55b833ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Conversation Summary: The customer reached out to customer care due to issues with their internet services. After initial troubleshooting attempts by the bot, the call was transferred to Agent Mark Dave. However, due to inactivity, the chat session was closed.']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADTTaMIVFJtv",
        "outputId": "e8fb2b11-d2bb-438f-9145-12fa7a949f25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Conversation Summary: The customer reached out to customer care due to issues with their internet services. After initial troubleshooting attempts by the bot, the call was transferred to Agent Mark Dave. However, due to inactivity, the chat session was closed.']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWyNagMLFaA0",
        "outputId": "0a735c3a-9813-42b2-bad8-b292012a54e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/outputs/simplet5-epoch-9-train-loss-0.4829-val-loss-0.3907': No such file or directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!cp -r \"/content/outputs/simplet5-epoch-9-train-loss-0.4829-val-loss-0.3907\" /content/drive/MyDrive/Falcon_fine_tuned_summ_models/T5_Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e9CBMaYFwnC"
      },
      "outputs": [],
      "source": [
        "conv='''Bot: Hi, I'm Giga, your virtual assistant. Give me a moment while I look up your account details.\n",
        "Bot: Bryan, I have your account details now, how may I help you?\n",
        "Customer: How does the eeros booster work?\n",
        "Bot: Almost done, thanks for your patience.\n",
        "Bot: I can help with internet troubleshooting.\n",
        "Bot: What issue are you experiencing? Wi-Fi connection, Can't connect plugged into modem, Slow speed, Can't access webpage, Something else\n",
        "Customer: Something else\n",
        "Bot: This issue will be best handled by an agent.\n",
        "Bot: One moment while I get someone to help.\n",
        "Bot: Thank you for waiting. You are now connected with Mark Dave\n",
        "Agent: Hi, Bryan! Welcome to our Fiber technical support chat. I apologize for the issues you are having with your internet services. Rest assured, I can check this for you. To begin with, may I have your account number and name, please?\n",
        "Agent: Just checking if you are still there, I haven't heard from you for a bit. I'll be here for few more minutes if you need my help.\n",
        "Agent: Thank you for contacting Technical Support. Due to inactivity, this chat session will be closed. If you need further assistance, please visit our website at Frontier.com or utilize the MyFrontier Mobile app. Feel free to start a new chat if you have any additional questions. Have a great rest of your day!\n",
        "Agent: Mark Dave has now closed this conversation. Please reach out to us if you need any assistance again.\n",
        "Agent: survey_process_initiated\n",
        "Customer: CSAT Rating\n",
        "Agent: survey_eligibility_conf'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAeNrCRW_eeT",
        "outputId": "3dedf4b3-bb1c-4d7d-f4d7-3c41786b8dfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Problem Statement: The customer is experiencing issues with their internet services.']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv+'\\n\\n'+p1, max_length =512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gH1s9NgJ_eeT",
        "outputId": "1ac5bd9c-27a0-4145-93b9-cfc1759ef184"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Conversation Summary: The customer reached out to customer care due to issues with their internet services. After initial troubleshooting attempts by the bot, the issue was escalated to Agent Mark Dave. However, due to inactivity, the chat session was closed.']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv, max_length =512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpIJJqDgO__y",
        "outputId": "7edc0424-5137-4373-c544-731a49d80ded"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Conversation Summary: The customer reached out to customer care due to issues with their internet services. After initial troubleshooting attempts by the bot, the issue was escalated to Agent Mark Dave. However, due to inactivity, the chat session was closed.']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsZq3FvIF2ON",
        "outputId": "ceaa7fd8-6c42-49b7-b29e-9560e69ce461"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Conversation Summary: The customer reached out to customer care due to issues with their internet services. After initial troubleshooting attempts by the bot, the issue was escalated to Agent Mark Dave. However, due to inactivity, the chat session was closed.']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "YPWgnS55_eeT",
        "outputId": "9dfffe76-2c93-4ed6-aafb-f5b4c5f40638"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 1024)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 1024)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 16)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-23): 23 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 1024)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 16)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-23): 23 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseGatedActDense(\n",
              "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): NewGELUActivation()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "T5MODELPATH=\"google/flan-t5-large\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(T5MODELPATH)\n",
        "model = T5ForConditionalGeneration.from_pretrained(T5MODELPATH)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "xEC7k7sX_eeT",
        "outputId": "8f38f2ce-4670-42b2-e1d7-42707086ccb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SwitchTransformersForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): SwitchTransformersStack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): SwitchTransformersLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): SwitchTransformersStack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersDenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): SwitchTransformersBlock(\n",
              "        (layer): ModuleList(\n",
              "          (0): SwitchTransformersLayerSelfAttention(\n",
              "            (SelfAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): SwitchTransformersLayerCrossAttention(\n",
              "            (EncDecAttention): SwitchTransformersAttention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): SwitchTransformersLayerFF(\n",
              "            (mlp): SwitchTransformersSparseMLP(\n",
              "              (router): SwitchTransformersTop1Router(\n",
              "                (classifier): Linear(in_features=768, out_features=8, bias=False)\n",
              "              )\n",
              "              (experts): ModuleDict(\n",
              "                (expert_0): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_1): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_2): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_3): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_4): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_5): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_6): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "                (expert_7): SwitchTransformersDenseActDense(\n",
              "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): ReLU()\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "            (layer_norm): SwitchTransformersLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): SwitchTransformersLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import SwitchTransformersForConditionalGeneration, AutoTokenizer\n",
        "T5MODELPATH=\"../notebooks/outputs_Dec12_summ_FlanT5Large_5epochs/simplet5-epoch-14-train-loss-0.3333-val-loss-0.1817\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(T5MODELPATH)\n",
        "model = SwitchTransformersForConditionalGeneration.from_pretrained(T5MODELPATH)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJNb93NI_eeT"
      },
      "outputs": [],
      "source": [
        "prompt1 = \"Generate the Problem Statement for the given conversation i.e, a one liner that briefs why the customer has reached out to an agent or the bot.\"\n",
        "prompt2 = \"For the given conversation, identify and extract key information such as names, important dates, emails, addresses, and any account details. Consider nuances like context, tone, and explicit mentions to grasp the essential information effectively.\"\n",
        "prompt3 = \"Generate the Emotion of the customer at the start of the given conversation.\"\n",
        "prompt4 = \"Give the summary for the given conversation.\"\n",
        "prompt5 = \"Generate the conclusion for the given conversation i.e, the final action taken to resolve the problem.\"\n",
        "prompt6 = \"Generate the next steps to be performed by the agent for the given conversation.\"\n",
        "l = [prompt1,prompt2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3sxemR9_eeT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def predict_batch(text):\n",
        "    # Add prefix and suffix to each input text\n",
        "\n",
        "    input_texts = [i+'\\n\\n'+text.strip() for i in l]\n",
        "    # input_texts.append(text + '\\n\\n' + p4)\n",
        "    input_texts_1 = text + '\\n\\n' + prompt4\n",
        "\n",
        "    # Encode input texts\n",
        "    start = time.time()\n",
        "    input_ids = tokenizer.batch_encode_plus(input_texts, return_tensors=\"pt\", padding=\"max_length\", max_length=512 , truncation=True, add_special_tokens=True).to(\"cuda\")\n",
        "\n",
        "    # Generate output texts using T5 model\n",
        "    outputs = model.generate(input_ids=input_ids[\"input_ids\"],max_length=64)\n",
        "    # outputs= model.generate(\n",
        "    #         input_ids=input_ids[\"input_ids\"],\n",
        "    #         num_beams=2,\n",
        "    #         max_length=128,\n",
        "    #         repetition_penalty=2.5,\n",
        "    #         length_penalty=1.0,\n",
        "    #         early_stopping=True,\n",
        "    #         # top_p=top_p,\n",
        "    #         top_k=50,\n",
        "    #         num_return_sequences=1,\n",
        "    #     )\n",
        "    predicted_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    input_ids_1 = tokenizer.encode(\n",
        "            input_texts_1, return_tensors=\"pt\", add_special_tokens=True\n",
        "        ).to(\"cuda\")\n",
        "    outputs = model.generate(input_ids=input_ids_1,max_length=256)\n",
        "    predicted_texts.extend(tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
        "    # print(time.time()-start)\n",
        "    # # Return predicted texts\n",
        "    return predicted_texts\n",
        "\n",
        "# ans = predict_batch(conv)\n",
        "# print(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_ehM0Vq_eeT",
        "outputId": "651cc261-815a-4bb3-925c-7c132382ce1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Problem Statement: Customer wants to see open tickets.', 'Key Information: Customer name: Renee Rios', 'Conversation Summary: The customer tries to connect with an agent for tickets, but the agent fails to establish the connection. The customer repeatedly requests to be transferred to a live agent, but the agent fails to establish the connection.']\n"
          ]
        }
      ],
      "source": [
        "conv = \"\"\"Agent:Zero for Alter Domus.\n",
        "Customer:That's zero.\n",
        "Agent:Press 1 for Mailinator.\n",
        "Agent:Press 2 for avmed.\n",
        "Agent:Press 3 for HYG.\n",
        "Agent:Press 4. For transcribe para ayuda en espanol pulse one For support in English, press 2.\n",
        "Customer:Actually the first Test.\n",
        "Agent:Hi I'm Aka's virtual assistant. I am here to help you with all your queries.\n",
        "Agent:I will need some details for verification purpose to proceed further. State your preference between employee ID or the first name to continue.\n",
        "Customer:First name.\n",
        "Agent:Tell me your name, please.\n",
        "Customer:Yes.\n",
        "Agent:For example, if your name is John Smith, say John.\n",
        "Customer:Rene.\n",
        "Agent:I heard Renee spelled as Rene.\n",
        "Agent:Is that right?\n",
        "Customer:Yes.\n",
        "Agent:Can you tell your last name please?\n",
        "Customer:Rios.\n",
        "Agent:I heard Rios spelled as Rios.\n",
        "Agent:Is that right?\n",
        "Customer:Yes.\n",
        "Agent:Hello Renee Rios, I can help you with tickets. What would you like to do today?\n",
        "Customer:Connect me to an agent.\n",
        "Agent:I will need to put you in touch with a live agent. Please wait while I transfer your call.\n",
        "Customer:So, hi, can you hear me?\n",
        "Customer:Hello. Hi.\n",
        "Customer:Show my open tickets.\n",
        "Customer:You are not audible.\"\"\"\n",
        "\n",
        "ans = predict_batch(conv)\n",
        "print(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np2Tjywi_eeT",
        "outputId": "02ba93e4-39a3-4db0-f721-bece07ad4882"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'predict_batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/ubuntu/str-summ/notebooks/Untitled28.ipynb Cell 37\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba10/home/ubuntu/str-summ/notebooks/Untitled28.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m conv \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mBot:Zero for Alter Domus.\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba10/home/ubuntu/str-summ/notebooks/Untitled28.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mBot:Press 1 for Mailinator.\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Ba10/home/ubuntu/str-summ/notebooks/Untitled28.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mBot:Press 2 for avmed.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba10/home/ubuntu/str-summ/notebooks/Untitled28.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mAgent:OK. Thanks for confirming. Is there anything else I can help you with?\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba10/home/ubuntu/str-summ/notebooks/Untitled28.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mCustomer:No, thank you. Bye.\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Ba10/home/ubuntu/str-summ/notebooks/Untitled28.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m ans \u001b[39m=\u001b[39m predict_batch(conv)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Ba10/home/ubuntu/str-summ/notebooks/Untitled28.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(ans)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict_batch' is not defined"
          ]
        }
      ],
      "source": [
        "conv = \"\"\"Bot:Zero for Alter Domus.\n",
        "Bot:Press 1 for Mailinator.\n",
        "Bot:Press 2 for avmed.\n",
        "Bot:Para Yuda en Espanol, Pulse One for support in English, press 2.\n",
        "Bot:Hi I'm Aka's virtual assistant. I am here to help you with all your queries.\n",
        "Bot:I will need some details for verification purpose to proceed further. State your preference between employee ID or the first name to continue.\n",
        "Customer:First name.\n",
        "Bot:Tell me your name, please.\n",
        "Bot:For example, if your name is John Smith, say John.\n",
        "Customer:Nene.\n",
        "Bot:I heard Eileen spelled as ELENE.\n",
        "Bot:Is that right?\n",
        "Customer:Yes.\n",
        "Customer:No.\n",
        "Bot:I'm sorry, I didn't catch that. Could you please repeat?\n",
        "Customer:Rene.\n",
        "Bot:I heard Eileen spelled as ELENE.\n",
        "Bot:Is that right?\n",
        "Customer:No.\n",
        "Bot:Let's try again. Tell me your name, please. For example, if your name is John Smith, say John.\n",
        "Customer:Rene.\n",
        "Bot:I heard Renee spelled as Rene.\n",
        "Bot:Is that right?\n",
        "Customer:Yes.\n",
        "Bot:Can you tell your last name please?\n",
        "Customer:Rios.\n",
        "Bot:I heard Rios spelled as Rios.\n",
        "Bot:Is that right?\n",
        "Customer:Yes.\n",
        "Bot:Hello Renee Rios, I can help you with tickets. What would you like to do today?\n",
        "Customer:Connect me to an agent.\n",
        "Bot:I will need to put you in touch with a live agent. Please wait while I transfer your call.\n",
        "Agent:Hello.\n",
        "Agent:Hi, how can I help you today?\n",
        "Customer:Hello.\n",
        "Agent:Hello. Hi.\n",
        "Customer:My system is hanging up. I need to raise an ticket on this.\n",
        "Agent:Sure. Let me help you with that.\n",
        "Agent:So I am raising a ticket on your booking. Somebody would connect with you.\n",
        "Customer:Like to connect with them respective purpose. The purpose can tell this name is OK directly so that I can connect directly.\n",
        "Agent:Sure, I'm looking for the contact of the person.\n",
        "Agent:I'll ping his contact number so that you can call him and get connected immediately.\n",
        "Customer:OK, sure. Thank you.\n",
        "Agent:So so the agents name is.\n",
        "Agent:Akhil, System Engineer. He will get in touch with you shortly.\n",
        "Customer:OK.\n",
        "Agent:Hope you received the e-mail. Can you please confirm your e-mail is rene.rios@the.com?\n",
        "Agent:OK. Thanks for confirming. Is there anything else I can help you with?\n",
        "Customer:No, thank you. Bye.\"\"\"\n",
        "\n",
        "ans = predict_batch(conv)\n",
        "print(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAjPxoG4_eeT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az9IHqlG_eeX",
        "outputId": "73f8b563-c76a-4d38-a18a-9c9c3ac0cfaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Problem Statement: The customer is locked out of their laptop.', 'Key Information: Customer name: Renee Rios', 'Conversation Summary: The customer was experiencing issues with their laptop, specifically being locked out. The bot was unable to assist with this and transferred the call to a live agent. The agent identified this as a high-priority issue and decided to escalate the ticket. The agent also created a ticket for the system engineer who would be reaching out to the customer. The ticket was escalated to the highest priority.']\n"
          ]
        }
      ],
      "source": [
        "conv = \"\"\"Bot:Zero for Alter Domus.\n",
        "Bot:Press 1 for Mailinator.\n",
        "Bot:Press 2 for avmed.\n",
        "Bot:Press 3 for HYG.\n",
        "Bot:Pair.\n",
        "Bot:Hi I'm Aka's virtual assistant. I am here to help you with all your queries.\n",
        "Bot:I will need some details for verification purpose to proceed further. State your preference between employee ID or the first name to continue.\n",
        "Customer:First name.\n",
        "Bot:Tell me your name, please.\n",
        "Bot:For example, if your name is John Smith, say John.\n",
        "Customer:Rene.\n",
        "Customer:Raining.\n",
        "Bot:I'm sorry, I didn't catch that. For example, if your name is John Smith, say John, tell me your name please. For example, if your name is John Smith, say John.\n",
        "Customer:Rene.\n",
        "Bot:I heard Renee spelled as Rene.\n",
        "Bot:Is that right?\n",
        "Customer:That's right.\n",
        "Bot:Can you tell your last name please?\n",
        "Customer:Rios.\n",
        "Bot:I heard Rios spelled as Rios.\n",
        "Bot:Is that right?\n",
        "Customer:That's right.\n",
        "Bot:Hello Renee Rios, I can help you with tickets. What would you like to do today?\n",
        "Customer:I have an issue with my system. I'm locked out.\n",
        "Bot:I am still learning to help you with this task. I will need to put you in touch with a live agent. Please wait while I transfer your call.\n",
        "Customer:Hello.\n",
        "Customer:Hello.\n",
        "Customer:Do you hear me?\n",
        "Customer:Hello.\n",
        "Agent:But the transcripts are looking good.\n",
        "Customer:Hello.\n",
        "Customer:Yeah, I can hear you now.\n",
        "Agent:No, I'm not able to hear you.\n",
        "Customer:Hello.\n",
        "Agent:OK. We can continue I think.\n",
        "Customer:So I have an issue with my laptop. I'm logged out so I've been trying since a while now. So OK is there anything you can? Is there a way you can help me out?\n",
        "Agent:How come that actually these kind of tickets are we considered as high priority tickets? So let me quickly raise the support ticket for this and get the engineer assigned to it.\n",
        "Customer:So I am in the office today. Can you know somebody can give me the contact of someone on the floor, the system engineer, so that I can get this resolved quickly?\n",
        "Agent:The system admin team, I think there will be some person on the floor who will, who will consult as high priority and they will be fixed. You can find you can find that guy in the entrance Bay you know.\n",
        "Customer:OK.\n",
        "Customer:It would be great if you could share me his contact number.\n",
        "Agent:Yeah, please reach out to him. Meanwhile, I will also create a ticket on this as a ticket will be required in order to perform the activity and I'll send out the details to your e-mail ID.\n",
        "Customer:Sure. I would like you to escalate the the highest priority.\n",
        "Agent:Sure. Yeah, let me do that. I'll I'll consider as a high priority ticket. OK.\n",
        "Customer:OK, then I think that is it from my end. Just share me the contact only with.\n",
        "Agent:OK, the engineer name will be Akhil so he will be reaching out to you. I'll I I just now created a ticket on this so you can reach out to him. Is there anything else I can help you with?\n",
        "Customer:This is it.\n",
        "Agent:Sure. Yeah. Thank you for calling the contact center. Have a nice day.\n",
        "Customer:Thank you. Good day. Bye.\"\"\"\n",
        "\n",
        "ans = predict_batch(conv)\n",
        "print(ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHo2zdf1_eeX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_test1 = pd.read_csv(\"/home/ubuntu/str-summ/ntt_test.csv\")\n",
        "df_test2 = pd.read_csv(\"/home/ubuntu/str-summ/struct_test_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbZiP2Ht_eeX",
        "outputId": "3848939e-a40d-48b9-b10c-dc04c3ae45f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bot:Zero for Alter Domus. \\nBot:Press 1 for Ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bot:Zero for Alter Domus. \\nCustomer:OK. \\nBot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Customer:transfer agent \\nBot:Welcome to AeroM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Customer:agent transfer \\nBot:You will be tran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bot:Zero for Alter Domus. \\nBot:Press 1 for Ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bot:Zero for Ultradomus. \\nBot:Press 1 for Mai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bot:Zero for Alter Domus. \\nBot:Press 1 for Ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bot:Welcome to AeroMexico \\nCustomer:agent \\nB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Customer:agent transfer \\nBot:Welcome to AeroM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Customer: hi\\nBot: Hello, I am ELSA, your virt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Customer: request item\\nBot: IMPORTANT: ChatNo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. Giv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Bot: Hi, I'm Giga, your virtual assistant. I'm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          source_text\n",
              "0   Bot:Zero for Alter Domus. \\nBot:Press 1 for Ma...\n",
              "1   Bot:Zero for Alter Domus. \\nCustomer:OK. \\nBot...\n",
              "2   Customer:transfer agent \\nBot:Welcome to AeroM...\n",
              "3   Customer:agent transfer \\nBot:You will be tran...\n",
              "4   Bot:Zero for Alter Domus. \\nBot:Press 1 for Ma...\n",
              "5   Bot:Zero for Ultradomus. \\nBot:Press 1 for Mai...\n",
              "6   Bot:Zero for Alter Domus. \\nBot:Press 1 for Ma...\n",
              "7   Bot:Welcome to AeroMexico \\nCustomer:agent \\nB...\n",
              "8   Customer:agent transfer \\nBot:Welcome to AeroM...\n",
              "9   Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "10  Customer: hi\\nBot: Hello, I am ELSA, your virt...\n",
              "11  Customer: request item\\nBot: IMPORTANT: ChatNo...\n",
              "12  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "13  Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "14  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "15  Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "16  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "17  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "18  Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "19  Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "20  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "21  Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "22  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "23  Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "24  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "25  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "26  Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "27  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "28  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "29  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "30  Bot: Hi, I'm Giga, your virtual assistant. Giv...\n",
              "31  Bot: Hi, I'm Giga, your virtual assistant. I'm...\n",
              "32  Bot: Hi, I'm Giga, your virtual assistant. I'm..."
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.DataFrame({\n",
        "    \"source_text\": list(df_test1['source_text']) + list(df_test2['source_text'])\n",
        "})\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVOrcaFe_eeX"
      },
      "outputs": [],
      "source": [
        "text = df_test[\"source_text\"].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4wHjgUc_eeX",
        "outputId": "f1dc8a80-cf47-4841-c251-5049808fb939"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "prob_state = []\n",
        "ki = []\n",
        "emo = []\n",
        "summ = []\n",
        "concl = []\n",
        "nextst = []\n",
        "for t in text:\n",
        "  # for p in prompt:\n",
        "  o=predict_batch(t)\n",
        "  prob_state+=[o[0]]\n",
        "  ki+=[o[1]]\n",
        "  # emo+=[o[2]]\n",
        "  summ+=[o[2]]\n",
        "  # concl+=[o[3]]\n",
        "  # nextst+=[o[4]]\n",
        "df_test[\"Problem Statement\"] = prob_state\n",
        "df_test[\"Key Information\"] = ki\n",
        "# df_test[\"Emotion\"] = emo\n",
        "df_test[\"Conversation Summary\"] = summ\n",
        "# df_test[\"Conclusion\"] = concl\n",
        "# df_test[\"Next steps\"] = nextst\n",
        "df_test.to_csv(\"../data/preds_Dec8_flanbase.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy5zHKlc_eeX",
        "outputId": "e886f1af-77f9-4296-be82-7b697daecfc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Key Information: Name : vincent Phone Number : 6263736072 Email Address : dank08@gmail.com Installation Date : 11/25/2023 Order Status : Secure']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(text[-1] + '\\n\\n' + p2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOt-60SO_eeX"
      },
      "outputs": [],
      "source": [
        "source_text = []\n",
        "for i in range(len(df_test)):\n",
        "    source_text += [df_test['source_text'][i]]*6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFXDH2TK_eeY"
      },
      "outputs": [],
      "source": [
        "test_df = pd.DataFrame({\n",
        "    'source_text': source_text,\n",
        "    'preds': x,\n",
        "    'instruction': instruction\n",
        "})\n",
        "test_df.to_csv('../data/preds_Dec4_summ_flanbase_5epochs.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u507oxvMPap5",
        "outputId": "489ce72f-e965-4cb9-e4e1-8afdfb4b66ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>x1,x2,x3,x4,x5,x6=[],[],[],[],[],[]                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> t <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> text:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>o1=model.predict(t + <span style=\"color: #808000; text-decoration-color: #808000\">'\\n\\n'</span> + p1)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>o2=model.predict(t + <span style=\"color: #808000; text-decoration-color: #808000\">'\\n\\n'</span> + p2)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>o3=model.predict(t + <span style=\"color: #808000; text-decoration-color: #808000\">'\\n\\n'</span> + p3)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>o4=model.predict(t + <span style=\"color: #808000; text-decoration-color: #808000\">'\\n\\n'</span> + p4)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/str-summ/notebooks/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">simplet5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">484</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>source_text, return_tensors=<span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>, add_special_tokens=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">482 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>input_ids = input_ids.to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>484 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>generated_ids = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.generate(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">485 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>input_ids=input_ids,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>num_beams=num_beams,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">487 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>max_length=max_length,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/torch/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_contextlib.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">115</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> ctx_factory():                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>115 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_context                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/generation/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1685</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1682 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>**model_kwargs,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1683 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1684 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># 13. run beam search</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1685 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.beam_search(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1686 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>input_ids,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1687 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>beam_scorer,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1688 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>logits_processor=logits_processor,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/generation/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3024</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">beam_search</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3021 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3022 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model_inputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prepare_inputs_for_generation(input_ids, **model_kwargs)  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3023 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3024 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3025 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>**model_inputs,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3026 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>return_dict=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3027 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>output_attentions=output_attentions,                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_t5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1746</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1743 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>decoder_attention_mask = decoder_attention_mask.to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.decoder.first_de  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1744 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1745 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Decode</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1746 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>decoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.decoder(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1747 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>input_ids=decoder_input_ids,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1748 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=decoder_attention_mask,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1749 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>inputs_embeds=decoder_inputs_embeds,                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_t5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1123</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># past_key_value is always None with gradient checkpointing</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1121 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1123 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>layer_outputs = layer_module(                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1124 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>attention_mask=extended_attention_mask,                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1126 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>position_bias=position_bias,                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_t5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">725</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 722 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 723 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>query_length = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 724 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 725 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>cross_attention_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layer[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>](                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 726 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>hidden_states,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 727 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>key_value_states=encoder_hidden_states,                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 728 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>attention_mask=encoder_attention_mask,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_t5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">636</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 633 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output_attentions=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 634 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>):                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 635 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>normed_hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.layer_norm(hidden_states)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 636 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attention_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.EncDecAttention(                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 637 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>normed_hidden_states,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>mask=attention_mask,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>key_value_states=key_value_states,                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_t5.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">532</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 531 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># compute scores</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 532 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>scores = torch.matmul(                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>query_states, key_states.transpose(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 534 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># equivalent of torch.einsum(\"bnqd,bnkd-&gt;bnqk\", query_states, key_states), co</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 535 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0mx1,x2,x3,x4,x5,x6=[],[],[],[],[],[]                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[94mfor\u001b[0m t \u001b[95min\u001b[0m text:                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 3 \u001b[2m  \u001b[0mo1=model.predict(t + \u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m + p1)                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m  \u001b[0mo2=model.predict(t + \u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m + p2)                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m  \u001b[0mo3=model.predict(t + \u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m + p3)                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m  \u001b[0mo4=model.predict(t + \u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m + p4)                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/home/ubuntu/str-summ/notebooks/\u001b[0m\u001b[1;33msimplet5.py\u001b[0m:\u001b[94m484\u001b[0m in \u001b[92mpredict\u001b[0m                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m481 \u001b[0m\u001b[2m│   │   │   \u001b[0msource_text, return_tensors=\u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m, add_special_tokens=\u001b[94mTrue\u001b[0m                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m482 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m483 \u001b[0m\u001b[2m│   │   \u001b[0minput_ids = input_ids.to(\u001b[96mself\u001b[0m.device)                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m484 \u001b[2m│   │   \u001b[0mgenerated_ids = \u001b[96mself\u001b[0m.model.generate(                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m485 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m486 \u001b[0m\u001b[2m│   │   │   \u001b[0mnum_beams=num_beams,                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m487 \u001b[0m\u001b[2m│   │   │   \u001b[0mmax_length=max_length,                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/torch/utils/\u001b[0m\u001b[1;33m_contextlib.py\u001b[0m:\u001b[94m115\u001b[0m in               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mdecorate_context\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_context\u001b[0m(*args, **kwargs):                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m ctx_factory():                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m115 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m decorate_context                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/generation/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m1685\u001b[0m in        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mgenerate\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1682 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m**model_kwargs,                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1683 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1684 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# 13. run beam search\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1685 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.beam_search(                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1686 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids,                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1687 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mbeam_scorer,                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1688 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mlogits_processor=logits_processor,                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/generation/\u001b[0m\u001b[1;33mutils.py\u001b[0m:\u001b[94m3024\u001b[0m in        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mbeam_search\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3021 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3022 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_inputs = \u001b[96mself\u001b[0m.prepare_inputs_for_generation(input_ids, **model_kwargs)  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3023 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3024 \u001b[2m│   │   │   \u001b[0moutputs = \u001b[96mself\u001b[0m(                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3025 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m**model_inputs,                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3026 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mreturn_dict=\u001b[94mTrue\u001b[0m,                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m3027 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput_attentions=output_attentions,                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/\u001b[0m\u001b[1;33mmodeling_t5.py\u001b[0m:\u001b[94m1746\u001b[0m in   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1743 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdecoder_attention_mask = decoder_attention_mask.to(\u001b[96mself\u001b[0m.decoder.first_de  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1744 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1745 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Decode\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1746 \u001b[2m│   │   \u001b[0mdecoder_outputs = \u001b[96mself\u001b[0m.decoder(                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1747 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=decoder_input_ids,                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1748 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=decoder_attention_mask,                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1749 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds=decoder_inputs_embeds,                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/\u001b[0m\u001b[1;33mmodeling_t5.py\u001b[0m:\u001b[94m1123\u001b[0m in   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1120 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mNone\u001b[0m,  \u001b[2m# past_key_value is always None with gradient checkpointing\u001b[0m    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1121 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1122 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1123 \u001b[2m│   │   │   │   \u001b[0mlayer_outputs = layer_module(                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1124 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1125 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask=extended_attention_mask,                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1126 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mposition_bias=position_bias,                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/\u001b[0m\u001b[1;33mmodeling_t5.py\u001b[0m:\u001b[94m725\u001b[0m in    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 722 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 723 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mquery_length = \u001b[94mNone\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 724 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 725 \u001b[2m│   │   │   \u001b[0mcross_attention_outputs = \u001b[96mself\u001b[0m.layer[\u001b[94m1\u001b[0m](                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 726 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhidden_states,                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 727 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mkey_value_states=encoder_hidden_states,                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 728 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mattention_mask=encoder_attention_mask,                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/\u001b[0m\u001b[1;33mmodeling_t5.py\u001b[0m:\u001b[94m636\u001b[0m in    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 633 \u001b[0m\u001b[2m│   │   \u001b[0moutput_attentions=\u001b[94mFalse\u001b[0m,                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 634 \u001b[0m\u001b[2m│   \u001b[0m):                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 635 \u001b[0m\u001b[2m│   │   \u001b[0mnormed_hidden_states = \u001b[96mself\u001b[0m.layer_norm(hidden_states)                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 636 \u001b[2m│   │   \u001b[0mattention_output = \u001b[96mself\u001b[0m.EncDecAttention(                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 637 \u001b[0m\u001b[2m│   │   │   \u001b[0mnormed_hidden_states,                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   │   │   \u001b[0mmask=attention_mask,                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   │   │   \u001b[0mkey_value_states=key_value_states,                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/venv/lib/python3.9/site-packages/transformers/models/t5/\u001b[0m\u001b[1;33mmodeling_t5.py\u001b[0m:\u001b[94m532\u001b[0m in    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 531 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# compute scores\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 532 \u001b[2m│   │   \u001b[0mscores = torch.matmul(                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m\u001b[2m│   │   │   \u001b[0mquery_states, key_states.transpose(\u001b[94m3\u001b[0m, \u001b[94m2\u001b[0m)                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 534 \u001b[0m\u001b[2m│   │   \u001b[0m)  \u001b[2m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), co\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 535 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x1,x2,x3,x4,x5,x6=[],[],[],[],[],[]\n",
        "for t in text:\n",
        "  o1=model.predict(t + '\\n\\n' + p1)\n",
        "  o2=model.predict(t + '\\n\\n' + p2)\n",
        "  o3=model.predict(t + '\\n\\n' + p3)\n",
        "  o4=model.predict(t + '\\n\\n' + p4)\n",
        "  o5=model.predict(t + '\\n\\n' + p5)\n",
        "  o6=model.predict(t + '\\n\\n' + p6)\n",
        "  x1.append(o1[0])\n",
        "  x2.append(o2[0])\n",
        "  x3.append(o3[0])\n",
        "  x4.append(o4[0])\n",
        "  x5.append(o5[0])\n",
        "  x6.append(o6[0])\n",
        "df_test[\"preds_Problem_statement\"] = x1\n",
        "df_test[\"preds_Key_Info\"] = x2\n",
        "df_test[\"preds_Emotion\"] = x3\n",
        "df_test[\"preds_Summary\"] = x4\n",
        "df_test[\"preds_Conclusion\"] = x5\n",
        "df_test[\"preds_Next_steps\"] = x6\n",
        "df_test.to_csv(\"../data/preds_flan_t5-5ep_nov30.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = \"anonymize\"\n",
        "a.split(\"/\")[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aIAaCyX0JtSc",
        "outputId": "c74c562b-7b0f-4fd7-969d-72c2b38da5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'anonymize'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0dbed5291b3c445baf19cafc785e359c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1efa939df64148c4b49646933c72dd68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfe9c42c25e44a480438fb5333bf352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f722a76a556440d9f5d5a6e414a526a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6e50082d4f4f3fa2277cfbdea58644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_968e6348f3ff41bc93b2e850ba8d83ad",
            "placeholder": "​",
            "style": "IPY_MODEL_95665c820724406a9bd9cc99ffa9f3ca",
            "value": "Epoch 0:   0%"
          }
        },
        "64e61411583f47d58789563f982c5dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "6cf2813a0154436ca2be1ff3c542649b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf4b606f93814f9d996e8c3f41d7caf6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bfe9c42c25e44a480438fb5333bf352",
            "value": 2
          }
        },
        "70bef647326448aaae5fb5cfb2b845cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f722a76a556440d9f5d5a6e414a526a",
            "placeholder": "​",
            "style": "IPY_MODEL_fccaa54662044d0e96796a7ae8bacf1a",
            "value": "Validation sanity check: 100%"
          }
        },
        "79fb0ef4f261427bb0050d056088875c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70bef647326448aaae5fb5cfb2b845cb",
              "IPY_MODEL_6cf2813a0154436ca2be1ff3c542649b",
              "IPY_MODEL_b1fab192919243808344b341039503b7"
            ],
            "layout": "IPY_MODEL_64e61411583f47d58789563f982c5dcc"
          }
        },
        "95665c820724406a9bd9cc99ffa9f3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "968e6348f3ff41bc93b2e850ba8d83ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa3b93fb5baf456e9808f28112b860a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafd04e9132e410c86f84111aba86911",
            "placeholder": "​",
            "style": "IPY_MODEL_f2813335be5a4ffaae5d95476b9658e1",
            "value": " 0/97 [00:00&lt;?, ?it/s]"
          }
        },
        "b090980aed3f4269863f8df32c03f89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b19d651940b541b6a94ce5f24c767f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dbed5291b3c445baf19cafc785e359c",
            "max": 97,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b090980aed3f4269863f8df32c03f89a",
            "value": 0
          }
        },
        "b1fab192919243808344b341039503b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1efa939df64148c4b49646933c72dd68",
            "placeholder": "​",
            "style": "IPY_MODEL_f11c4e5bdbc14898a8f7e4c0fa8e4b98",
            "value": " 2/2 [00:04&lt;00:00,  2.01s/it]"
          }
        },
        "becba7169d8249ec8926de275f2f8c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f6e50082d4f4f3fa2277cfbdea58644",
              "IPY_MODEL_b19d651940b541b6a94ce5f24c767f1a",
              "IPY_MODEL_aa3b93fb5baf456e9808f28112b860a8"
            ],
            "layout": "IPY_MODEL_f2ac66de89f24c15a56ab84ec8c53917"
          }
        },
        "bf4b606f93814f9d996e8c3f41d7caf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafd04e9132e410c86f84111aba86911": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f11c4e5bdbc14898a8f7e4c0fa8e4b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2813335be5a4ffaae5d95476b9658e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2ac66de89f24c15a56ab84ec8c53917": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "fccaa54662044d0e96796a7ae8bacf1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}